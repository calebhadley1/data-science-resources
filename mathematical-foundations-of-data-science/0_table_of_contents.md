# Table of Contents

1. Overview, and Data and Uncertainty
    - Data Science Overview
        - [Patterns, Predictions and Actions](1_patterns_predictions_and_actions.md)
            - Chapter 1 - Introduction
            - Chapter 2 - Fundamentals of Prediction
        - [Elementary Statistics](2_elementary_statistics.md)
            - Chapter 1.1 - Stats key concepts
    - Data and Uncertainty
        - [Deep Learning](3_deep_learning.md)
            - Chapter 3.1 - Why Probability?
        - [Mathematics for Machine Learning](4_mathematics_for_machine_learning.md)
            - Page 6 - Table of Symbols
            - Chapter 2.2 - Matrices
2. Sampling and Descriptive Statistics
    - Descriptive Statistics
        - [Statistical Thinking](https://www.youtube.com/playlist?list=PLRKtJ4IpxJpBxX2S9wXJUhB1_ha3ADFpF)
        - [Density Curves: Modeling Data Distributions](https://www.youtube.com/watch?v=PUvUQMQ7xQk)
        - [Mean, Median and Skew from Density Curves](https://www.youtube.com/watch?v=JFesFhraX2M)
        - [Mathematics for Machine Learning](4_mathematics_for_machine_learning.md)
            - Chapter 6.4
        - [MatPlotLib Histograms](https://matplotlib.org/stable/plot_types/stats/hist_plot.html)
        - [Applied Linear Algebra](6_applied_linear_algebra_intro.md)
            - Chapter 3.3 - Standard Deviation
        - Key concepts:
            - Descriptive stats
            - Variance
            - Standard deviation
            - Quantiles
            - Skew
    - Resampling Data
        - [Bootstrapping Main Ideas](https://www.youtube.com/watch?v=Xz0x-8-cgaQ)
        - [The Danger of Overfitting](youtube.com/watch?v=Ux3X97nfHSE&list=PLRKtJ4IpxJpDxl0NTvNYQWKCYzHNuy2xG&index=50)
        - [The Importance of Data Spliting](https://www.youtube.com/watch?v=L5rA1MsGXtA&list=PLRKtJ4IpxJpDxl0NTvNYQWKCYzHNuy2xG&index=52)
3. What Models Do and Managing Model Errors
    - What do Models do?
        - [Mathematics for Machine Learning](4_mathematics_for_machine_learning.md)
            - Chapter 8 - 8.1 - Matrices
        - [Applied Linear Algebra](6_applied_linear_algebra_intro.md)
            - Chapter 2.1 - Linear Functions
    - Managing Errors
        - [Mathematics for Machine Learning](4_mathematics_for_machine_learning.md)
            - Chapter 9 - 9.1 - Linear Regression
        - [Principles of Risk Minimization for Learning Theory - Vladimir Vapnik](https://proceedings.neurips.cc/paper_files/paper/1991/hash/ff4d5fbbafdf976cfdc032e3bde78de5-Abstract.html)
            - Describes the function estimation model
            - A good youtube video to accompany this is: https://www.youtube.com/watch?v=Ow25mjFjSmg
        - [Deep Learning](3_deep_learning.md)
            - Chapter 4.3 -  Gradient Based Optimization
        - [R-squared or coefficient of determination | Regression | Probability and Statistics | Khan Academy](https://www.youtube.com/watch?v=lng4ZgConCM)
        - [Measuring the fit of a regression model: R^2](https://mcrovella.github.io/DS701-Tools-for-Data-Science/17-Regression-I-Linear.html#measuring-the-fit-of-a-regression-model-r-2)
        - [Statistical Forecasting: Notes on Regression and Time Series Analysis, Whatâ€™s a Good Value for R-Squared?](https://people.duke.edu/~rnau/rsquared.htm)
    - Ordinary Least Squares Regression
        - [Linear Models](https://mcrovella.github.io/DS701-Tools-for-Data-Science/17-Regression-I-Linear.html)
            - Covers concepts like Design matrix (independent vars, matrix X), Observation matrix (dependent vars, vector y), Parameter vector (model params), Observed vs predicted, Residuals, Least squares line (minimizes the sum of the squares of the risiduals), Regression coefficients, Multiple regression, R^2
        - [Mathematics for Machine Learning](4_mathematics_for_machine_learning.md)
            - Chapter 9 - 9.2.2 - Linear Regression. Finish the rest of this section that wasn't covered in Managing Errors section
4. Fitting Models to Data
    - Model Parameter Fiting
        - Key concepts:
            - Parameters of decision trees vs linear regression
    - Calculating Gradients
        - [Derivatives at Wolfram Mathworld](https://mathworld.wolfram.com/Derivative.html)
        - [The paradox of the derivative](https://www.youtube.com/watch?feature=shared&v=9vKqVkMQHKk)
        - [Derivatives through geometry](https://www.youtube.com/watch?v=S0_qX4VJhMQ)
        - Key concepts:
            - Gradients
            - Limits (one and two sized)
            - Differentiability
            - Derivative
                - Partial derivatives
                - Derivatives of Linear Functions of One Variable
                - Partial Derivatives of a Linear Function with Multiple Variables
                - Derivatives of Constants
                - Derivatives of Variables
                - Derivatives of Sums
                - Derivatives of Scaled Functions
                - Rules for Combining Derivative Expressions
                - Derivatives of Common Functions
            - Extrema
                - Zero Gradients and Local Extrema
                - Local Extrema Without Zero Gradients
                - Convex Functions
            - Polynomials
                - Polynomial Gradients and Linear Regressions
                - Deriving the Derivative of a Monomial
                - Derivatives of a Polynomial
            - Deriving the Minimum Loss Parameters of a Linear Model
5. Introduction to Random Variables
    - Introduction to Random Variables
        - [Mathematics for Machine Learning](4_mathematics_for_machine_learning.md)
            - Chapter 6-6.1: Probability and Distributions
        - Key concepts:
            - Probability Distribution
            - Entropy
            - Perplexity
            - Sample Distribution 
            - Sample Probability
            - Resampling
            - Mean of a Probability Distribution
            - Variance of a Probability Distribution
    - Boolean Random Variables
        - [Mathematics for Machine Learning](4_mathematics_for_machine_learning.md)
            - Chapter 6.2-6.2.1: Discrete and Continuous Probabilities
        - Key concepts:
            - Bernoulli Distributions
            - Uniform Random Numbers
            - Sampling Boolean Random Variables
            - Modeling Boolean Random Variables
            - Calculating Sample Distributions From True Probabilities
    - Continuous Random Variables
        - [Mathematics for Machine Learning](4_mathematics_for_machine_learning.md)
            - Finish the rest of Chapter 6.2
            - Chapter 6.5: Gaussian Distributions
        - Key concepts:
            - Boolean vs Continuous Random Variables
            - Probability Density Functions
            - Gaussian Distribution
            - Standard Normal Distribution
            - Calculating Means From Probability Density Functions
            - Calculating Variances From Probability Density Functions
            - Cumulative Distribution Function
            - Sampling Continuous Distributions
6. Relationship Between Random Variables
    - Marginal and Conditional Probabilities
        - [Mathematics for Machine Learning](4_mathematics_for_machine_learning.md)
            - Chapter 6.3: Sum Rule, Product Rule, and Bayes' Theorem
        - [Bayes' Theorem Proof](https://www.youtube.com/watch?v=U_85TaXbeIo)
        - Key concepts:
            - Univariate, bivariate and multivariate distributions
            - Marginal and Conditional distibutions on ndarrays and DataFrames
            - Conditional Distributions
                - ![alt text](conditional_distribution_formula.png)
            - Bayes' Theorem
                - ![alt text](bayes_theorem.png)
            - Conditional Probability Density Functions  
    - Independence and Correlation
        - [Mathematics for Machine Learning](4_mathematics_for_machine_learning.md)
            - Chapter 6.4: Summary Statistics and Independence
        - Key concepts:
            - Independent Boolean Random Variables
                - ![alt text](boolean_random_variable_independence.png)
            - Chained Dependencies and Potential Fallacies
            - Correlations Between Random Variables
                - Pearson's Correlation Coefficient
            - Sums of Random Variables
                - How it applies to independent vs correlated normally distributed variables
7. The Law of Large Numbers, Central Limit Theorem, and Hypothesis Testing
    - Central Limit Theorem
        - [Intro to Limits](https://www.youtube.com/watch?feature=shared&v=poBobcFn1Co)
        - [Law of Large Numbers - Khan Academy](https://www.youtube.com/watch?v=VpuN8vCQ--M)
        - [Why we gamble like monkeys (correlary to law of large numbers)](https://www.bbc.com/future/article/20150127-why-we-gamble-like-monkeys)
        - [Gambler's Fallacy](https://www.youtube.com/watch?v=XA_0OMJjkxQ)
        - Key concepts:
            - Reading limit notation
            - Finite vs Infinite Limits
            - The Law of Large Numbers
    - Hypothesis Testing
        - [Patterns Predictions and Actions Chapter 2 (Errors and ROC curves)](1_patterns_predictions_and_actions.md)
        - [Type I vs II Errors](https://www.youtube.com/watch?v=SBt7q2m_Ncw)
        - [Classification: ROC Curves and AUC](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)
        - [Elementary Stats - Chapter 1.4.1, 4.2 (except 4.2.2)](2_elementary_statistics.md)
        - [Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations](https://link.springer.com/article/10.1007/s10654-016-0149-3)
        - [What is a p-value](https://www.youtube.com/watch?v=9jW9G8MO4PQ&list=PLRKtJ4IpxJpDsOT_8YDREJrO8cQUtPUVg&index=10&pp=iAQB)
        - [How do you get a p value?](https://www.youtube.com/watch?v=9jW9G8MO4PQ&list=PLRKtJ4IpxJpDsOT_8YDREJrO8cQUtPUVg&index=10&pp=iAQB)
        - [How to use p-values and significance levels](https://www.youtube.com/watch?v=lJSTfhkB5zw&list=PLRKtJ4IpxJpDsOT_8YDREJrO8cQUtPUVg&index=12&pp=iAQB)
        - [The Problem of Multiple Comparisons](https://www.youtube.com/watch?v=HpjlcEH4zuY)
        - Key concepts:
            - Errors (Type I and II)
            - ROC Curves
            - AUC
            - P Values, Confidence Intervals, and Power
            - Signifiance Levels in relation to P Values
            - The Problem of Multiple Comparisons
8. Motivations for Linear Algebra
    - Why Linear Algebra
        - [Math for ML - Chapter 2: Linear Algebra (Up to 2.2)](4_mathematics_for_machine_learning.md)
        - [Vectors | Chapter 1, Essence of linear algebra](https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)
        - [Math for ML - Chapter 7.3.1: Linear Programming](4_mathematics_for_machine_learning.md)
        - Key concepts:
            - How Linear algrebra is used in ML
    - Principle Components Analysis
        - [Mathematics of Machine Learning, Chapter 10-10.2 Dimensionality Reduction with Principal Components Analysis](4_mathematics_for_machine_learning.md)
        - [Principal Component Analysis](https://www.youtube.com/watch?v=FD4DeN81ODY)
        - Key concepts:
            - PCA as identifies common directions of variation in a dataset
9. Introduction to Vectors
    - Basic Vectors Concepts
        - [Vector Equations](https://mcrovella.github.io/CS132-Geometric-Algorithms/L04VectorEquations.html)
        - [Mathematics of Machine Learning, Chapter 2-2.1 Linear Algebra](4_mathematics_for_machine_learning.md)
        - [Introduction to Applied Linear Algebra, Chapters 1-1.3](6_applied_linear_algebra_intro.md)
        - [Introduction to Applied Linear Algebra, Chapters 3.1: Norm](6_applied_linear_algebra_intro.md)
        - [Introduction to Applied Linear Algebra, Chapters 3.2: Distance](6_applied_linear_algebra_intro.md)
    - Vector Similarity Measures
        - [Introduction to Applied Linear Algebra, Chapter 5.1: Linear Dependence](6_applied_linear_algebra_intro.md)
        - [Mathematics for Machine Learning, Chapter 2.5: Linear Independence](4_mathematics_for_machine_learning.md)
