# Table of Contents

1. Introduction to Machine Learning
    - [An Introduction to Statistical Learning: With Applications in Python](1_introduction_to_statistical_learning.md) - Chapter 1-2.1.1, 2.1.4
    - [Hands-on machine learning with Scikit-Learn, Keras and TensorFlow](2_hands_on_machine_learning_with_sklearn_keras_and_tensorflow.md) - Chapter 1 (pages 1-26)
    - [Introduction to ML: What is Machine Learning? | ML for Beginners](https://www.youtube.com/watch?v=bk12t0Xz5FM)
    - [AI, Machine Learning, Deep Learning and Generative AI Explained](https://www.youtube.com/watch?v=qYNweeDHiyU)
    - [Supervised & Unsupervised Machine Learning](https://www.youtube.com/watch?v=wvODQqb3D_8)
    - [Humans are biased. Generative AI is even worse (Bloomberg.com)](https://www.bloomberg.com/graphics/2023-generative-ai-bias/)
    - [How I'm fighting bias in algorithms | Joy Buolamwini (TED)](https://www.youtube.com/watch?v=UG_X_7g63rY)
    - Key concepts:
        - Describe the basic types of machine learning algorithms and the problems they address
        - Explain the importance of creating ML models that generalize to unseen data
        - Compare prediction and inference in obtaining results
        - Explain the issues of accuracy and interpretability in evaluating the results obtained
        - Explain the difference between reducible and irreducible errors and their sources
        - Summarize the bias-variance tradeoff in evaluating models
        - Identify how biased data can compromise your results and lead to unfair outcomes
    - Key terms:
        - Machine Learning (ML): A field of AI where algorithms learn from data to make predictions or decisions without explicit programming
        - Training Set: A dataset used to train a machine learning model by adjusting its parameters to minimize error
        - Testing Set: A dataset used to evaluate the performance of a trained model and estimate its generalization to new, unseen data
        - Supervised Learning: A type of ML where models learn from labeled data to predict outcomes
        - Unsupervised Learning: A type of ML where models find patterns or structures in unlabeled data
        - Regression: A supervised ML technique used to predict real-valued outcomes
        - Classification: A supervised ML technique for categorizing data into distinct classes
        - Clustering: An unsupervised ML technique that groups similar data points based on their features
        - Dimensionality Reduction: A ML technique that combines the information from multiple input variables into fewer dimensions, retaining the most important patterns and structure in the data
        - Prediction: Using a model to calculate outcomes based on new data not included in the training set
        - Inference: Drawing conclusions about relationships between variables in the data
        - Generalization: The ability of a machine learning model to perform well on new, unseen data by effectively capturing underlying patterns during training rather than memorizing the specific details of the training set
        - Reducible Error: The part of a model's error that can be minimized by improving the model 
        - Irreducible Error: The portion of the error that cannot be eliminated, caused by inherent noise or randomness in the data regardless of the model used
        - Bias (of a model): The error introduced by using a model that is too simple to capture the complexity of the underlying data patterns 
        - Variance: The error introduced because the model is too complex and sensitive to fluctuations in the training data, capturing noise along with the underlying pattern
        - Underfitting: A situation where the model is not complex enough, resulting in high bias 
        - Overfitting: A situation where the model is too complex, resulting in high variance 
        - Accuracy: Used formally to refer to the percentage of correct predictions for classification models; used informally to refer to how well a model performs 
        - Interpretability: The ability for a human to understand how a machine learning model makes decisions
        - Bias (of a dataset): Errors or distortions in the data that result in unfair or unequal outcomes, often reflecting societal inequalities or imbalanced data collection
        - Fairness: Ensuring models do not produce biased or discriminatory outcomes
2. Linear Regression
    - [An Introduction to Statistical Learning: With Applications in Python](1_introduction_to_statistical_learning.md) - Chapter 3 Section 1 and Section 2-2.1, Chapter 5 Section 2
    - [Hands-on machine learning with Scikit-Learn, Keras and TensorFlow](2_hands_on_machine_learning_with_sklearn_keras_and_tensorflow.md) - Chapter 4 (pages 131-154)
    - [Video 1: Introduction to Simple Linear Regression](https://www.youtube.com/watch?v=owI7zxCqNY0)
    - [Deriving the least squares estimators of the slope and intercept (simple linear regression)](https://www.youtube.com/watch?v=ewnc1cXJmGA)
    - [Gradient Descent Explained](https://www.youtube.com/watch?v=i62czvwDlsw)
    - [Multiple Regression | Ch. 4, Linear Regression](https://www.youtube.com/watch?v=xVgqM35YSDY)
    - Key concepts:
        - Linear Regression
        - Multiple Regression
        - Polynomial Regression
        - Gradient Descent
        - Mean Square Error (MSE)
        - Root Mean Square Error
        - Coefficient of Determination or R squared
        - Assumptions of Linear Regression: Includes linearity, independence of errors, normality with mean 0, and homoscedasticity (constant variance of errors across all levels of the independent variables)
        - Hyperparameters
3. Generalization, Errors, and the Bias-Variance Tradeoff
    - [An Introduction to Statistical Learning: With Applications in Python](1_introduction_to_statistical_learning.md) - Chapter 2 Section 2.1: Measuring the Quality of Fit
    - [Generalization and Overfitting](https://www.youtube.com/watch?v=ggkSrsxa5kU)
    - [Bias-Variance Tradeoff](https://www.youtube.com/watch?v=UiYGlz6BVFs)
    - Key concepts:
        - Underfitting and overfitting
        - Generalization
        - Bias-variance tradeoff
4. Generalization; Sampling Methods: Training, Testing, and Validation Sets; Cross-Validation
    - [Stats 101: What is the â€‹Sampling Theory](https://thinkingneuron.com/what-is-the-sampling-theory/)
    - [Hands-on machine learning with Scikit-Learn, Keras and TensorFlow](2_hands_on_machine_learning_with_sklearn_keras_and_tensorflow.md) Read Chapter 2, End-to-End Machine Learning Project, pp. 88-89, Chapter 4, Training Models, pp.151-154
    - [Why do we split data into train test and validation sets?](https://www.youtube.com/watch?v=dSCFk168vmo)
    - [Machine Learning Fundamentals: Cross Validation](https://www.youtube.com/watch?v=fSytzGwwBVw&t=165s)
    - Key concepts:
        - Training Set
        - Test Set
        - Validation Set
        - Train-Validation-Test Split
        - Cross-Validation
        - Leave-One-Out Cross Validation
5. Feature Selection and Regularization
    - [An Introduction to Statistical Learning: With Applications in Python](1_introduction_to_statistical_learning.md) -Read Deciding on Important Variables, pp. 86-87 carefully as it contains a rigorous explanation of feature selection. 
    - [Hands-on machine learning with Scikit-Learn, Keras and TensorFlow](2_hands_on_machine_learning_with_sklearn_keras_and_tensorflow.md) Read Chapter 4, Training Models, pp. 155-161
    - [How to Choose a Feature Selection Method For Machine Learning](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/)
    - [Regularization](https://www.youtube.com/watch?v=8t5vaZroVjw)